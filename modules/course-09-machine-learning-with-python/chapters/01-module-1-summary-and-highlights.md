# Course 9, Module 1: Summary and Highlights

## Overview
This module introduces the ML landscape: problem types, learning paradigms, core tools, and where various libraries and frameworks fit across classical and deep learning.

## Concepts
- AI simulates human cognition; ML learns from data with algorithms and feature engineering.
- Learning paradigms: supervised (labeled), unsupervised (unlabeled patterns), semi-supervised (small labeled subset).
- Choose techniques based on problem type, data, resources, and outcomes.

## Techniques and Use Cases
- Anomaly detection for unusual cases (e.g., fraud).
- Classification for categorizing new data.
- Regression for predicting continuous values.
- Clustering for grouping similar points without labels.

## Tools and Ecosystem
- Pipelines span preprocessing, modeling, evaluation, optimization, and deployment.
- Languages: R for statistics/exploration; Python for broad ML; Julia/Scala/Java/JavaScript for performance, big data, and web ML.
- Visualization: Matplotlib, Seaborn, ggplot2; dashboards with Tableau.
- Python libraries: NumPy, Pandas, SciPy, Scikit-learn for classical ML.
- Deep learning: TensorFlow, Keras, Theano, PyTorch for vision and NLP.
- NLP: NLTK, TextBlob, Stanza; CV: object detection, image classification, face recognition.
- Generative AI: create text, images, music, and other media from prompts/data.
- Scikit-learn functions: classification, regression, clustering, preprocessing, evaluation, and model export.
- The ML ecosystem integrates tools, frameworks, platforms, and processes to build and manage models end to end.

## Takeaways
- Match techniques to problem types and data availability.
- Use Python + Scikit-learn for fast prototyping of classical ML.
- Explore deep learning frameworks for vision and NLP tasks.

